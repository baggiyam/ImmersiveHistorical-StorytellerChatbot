{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ee7b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from context_format import retrieve_context, format_context\n",
    "from SimpleConversationMemory import SimpleConversationMemory\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pinecone import Pinecone, ServerlessSpec \n",
    "import uuid\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain_core.documents import Document \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import re\n",
    "import pyttsx3\n",
    "import uuid\n",
    "from IPython.display import Audio, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3d86398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "def speak_text(text: str, rate: int = 150, volume: float = 0.9):\n",
    "    \"\"\"Speak the given text aloud (non‑blocking). Keeps original prints intact.\"\"\"\n",
    "    if not text:\n",
    "        return\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty(\"rate\", rate)\n",
    "        engine.setProperty(\"volume\", volume)\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    except Exception as e:\n",
    "        # If TTS fails, just continue without crashing the program\n",
    "        print(\"[TTS error]\", e)\n",
    "\n",
    "\n",
    "def safe_parse_json(llm_output: str):\n",
    "    try:\n",
    "        return json.loads(llm_output)\n",
    "    except json.JSONDecodeError:\n",
    "        cleaned = llm_output.strip()\n",
    "\n",
    "        # Escape newlines and backslashes more aggressively\n",
    "        cleaned = re.sub(r'(?<!\\\\)\\\\n', '\\\\\\\\n', cleaned)\n",
    "        cleaned = re.sub(r'(?<!\\\\)\\\\\\\\', '\\\\\\\\', cleaned)\n",
    "\n",
    "        # Remove any control chars that are not allowed in JSON strings\n",
    "        cleaned = re.sub(r'[\\x00-\\x1f\\x7f]', '', cleaned)\n",
    "\n",
    "        try:\n",
    "            return json.loads(cleaned)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"❌ Still can't parse JSON after cleaning:\", e)\n",
    "            print(\"🧾 Raw output:\", llm_output)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e80270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_text(text, rate=150, volume=0.9):\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty('rate', rate)\n",
    "        engine.setProperty('volume', volume)\n",
    "\n",
    "        # Generate unique file name\n",
    "        filename = f\"/mnt/data/narration_{uuid.uuid4().hex}.wav\"\n",
    "        engine.save_to_file(text, filename)\n",
    "        engine.runAndWait()\n",
    "\n",
    "        # Play audio in notebook\n",
    "        display(Audio(filename))\n",
    "    except Exception as e:\n",
    "        print(\"Narration failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "045b0aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎭 Welcome to Immersive Storytelling!\n",
      "🌍 Where would you like to go today?\n",
      "   ✨ Options: Great Pyramids, Roman Forum, Ancient Greece, Machu Picchu, Mesopotamia, Sangam Tamil Civilization\n",
      "--------------------------------------------------\n",
      "🗺 Destination/Query: Mesopotamia\n",
      "🔍 Retrieving context...\n",
      "📖 Generating immersive story...\n",
      "\n",
      "📚 Your Immersive Journey:\n",
      "\n",
      "📝 Story:\n",
      " Let me transport you back in time, to the cradle of civilization, the land known as Mesopotamia. Imagine the soft, humid air, rich with the scent of fertile earth irrigated by the flowing waters of the Tigris and Euphrates rivers. Listen to the rustling of the reeds and the whispering of the wind as it sways the branches of date palms. As far as your eyes could see, the emerald canvas of floodplains stretches, testifying to the labor of farming communities who have tilled this land since prehistoric times, as early as 10,000 BCE. The rhythmic clink of tools and the distant hum of merchant conversations fill the air as societies of astounding complexity spring from the earth. Welcome to the world's earliest cities and states, the bustling urban metropolises of Uruk, Ur, and Eridu. The air vibrates with energy and excitement, echoing with the haggling of merchants and the chatter of craftsmen. Picture the streets filled with farmers, soldiers, and slaves, all playing their parts in this class-based society. The heart of each city is a towering ziggurat, a temple complex that punctuates the skyline, dedicated to a patron deity and a symbol of the religion that is central to Sumerian life. As the sun sets, see the clay tablets etched with cuneiform, the world's first writing system, catching the last golden rays, bearing stories of record-keeping, literature, and law. This is Mesopotamia, a vital crossroads of early human civilization where the course of history was shaped.\n",
      "\n",
      "🎬 Referenced Videos: fBOD64ow5eo\n",
      "\n",
      "🤔 Follow-up: do you want to know Can you tell me more about the role of cuneiform in the growth and complexity of these early cities?? (yes/no)\n",
      "🗺 Destination/Query: Mesopotamia\n",
      "🔍 Retrieving context...\n",
      "📖 Generating immersive story...\n",
      "\n",
      "📚 Your Immersive Journey:\n",
      "\n",
      "📝 Story:\n",
      " Steep yourself in the mystic aura of the land nestled between the Tigris and Euphrates rivers - Mesopotamia, the cradle of civilization. Picture the verdant expanse of emerald floodplains, vibrant and pulsating with life, nourished by the sprawling rivers that have etched life into the core of this ancient landscape since the dawn of human settlement. From the earliest farming communities of 10,000 BCE to bustling cities that rose from the dust, Mesopotamia has been a testament to evolution itself. The air here hums with the echoes of the past; the murmur of bustling markets, the rhythmic thud of farmers tilling the fertile soil, and the fervent whispers of priest-kings in temple complexes. Let the scent of freshly harvested crops from the fertile plains, the earthy aroma of the clay tablets bearing the insignia of cuneiform, and the lingering incense from the ziggurats lead you through time. Lose yourself among the shadows of bygone city-states like Uruk, Ur, and Eridu, where political machinations, economic prowess, and spiritual devotion swirled together in a vibrant tapestry of life. Where the echo of the scribe's stylus scraping against clay tablets resonates, and the spiritual chants of worshipers in colossal ziggurats ascend to the heavens. This is Mesopotamia, the realm of Sumerians, where every stone, every river bend, every gust of wind carries the legacy of one of the world's earliest civilizations.\n",
      "\n",
      "🎬 Referenced Videos: fBOD64ow5eo\n",
      "\n",
      "🤔 Follow-up: do you want to know Can you elaborate on the roles of the cities Uruk, Ur, and Eridu in the development of early civilization and their influence on modern society?? (yes/no)\n",
      "🗺 Destination/Query: Can you elaborate on the roles of the cities Uruk, Ur, and Eridu in the development of early civilization and their influence on modern society?\n",
      "🔍 Retrieving context...\n",
      "📖 Generating immersive story...\n",
      "\n",
      "📚 Your Immersive Journey:\n",
      "\n",
      "📝 Story:\n",
      " Close your eyes and journey back, thousands of years into the past, to the dawn of civilization, where the ancient cities of Uruk, Ur, and Eridu shaped the course of human history. Imagine the bustling city of Uruk, one of the first major cities in the world. Feel the sun-drenched stone of the massive walls, protecting a population that might have numbered more than 50,000 at its height around 3000 BCE. Listen to the murmur of scribes as they etch into clay tablets, evolving the earliest forms of writing from simple pictographs into the complex beauty of cuneiform script.  Here, in the heart of the city, stands the legendary home of King Gilgamesh, the hero of the oldest known epic poem, The Epic of Gilgamesh. Hear his epic tales echoing through the grand halls, their every word a testament to the power of the written word.  Now, shift your gaze to the city of Ur, famous for its monumental Ziggurat, a massive stepped temple built around the 21st century BCE in honor of the moon god Nanna. Feel the cool evening breeze as you ascend the temple steps, high above a city pulsating with religious and cultural fervor. Look at the shimmering treasures excavated from its royal tombs - golden artifacts, intricate jewelry, and ancient musical instruments, each a testament to the city's rich heritage. This is the city traditionally considered the birthplace of the biblical patriarch Abraham, weaving it into the tapestry of religious history.  However, the story of Uruk and Ur remains incomplete without the details of Eridu. Unfortunately, the context provided is insufficient to describe this city in detail. Yet, know that each of these ancient cities, in their own unique way, played a critical part in molding the civilization we know today.\n",
      "\n",
      "🎬 Referenced Videos: fBOD64ow5eo\n",
      "\n",
      "🤔 Follow-up: do you want to know What was the significance of the Eanna precinct dedicated to the goddess Inanna in Uruk's society and culture?? (yes/no)\n",
      "🗺 Destination/Query: Rome\n",
      "🔍 Retrieving context...\n",
      "📖 Generating immersive story...\n",
      "\n",
      "📚 Your Immersive Journey:\n",
      "\n",
      "📝 Story:\n",
      " Close your eyes and imagine stepping into a time machine, taking you back, more than two thousand years, to the heart of ancient Rome. A bustling city of gods and men, the first superpower of the world, born from the strategic location chosen by divine hands. You would find yourself among hills of pure air, breathing in the echoes of historical conquests. The Tiber River, vital and convenient, ushering forth prosperity, its cool breeze carrying the scent of the nearby Mediterranean Sea. As the sun sets, painting the sky with hues of mesmerizing gold, the city comes alive, its heartbeat echoing off the formidable walls of the fortified settlement that would rise as a powerful republic, and finally, an empire.  In the heart of this metropolis stands the grand Colosseum, an immovable testament to Roman ambition. The roar of the crowd and the clash of gladiator swords resonates within the amphitheater, a symbol of Rome's strength and fealty to entertainment. Away in the distance, the bell tower of the Basilica of Santa Francesca Romana, dating back to the 12th century, proudly overlooks the city, its dulcet tolls echoing across Rome's terracotta rooftops. In a quiet corner of the city, the museum of the Roman Forum presents yet another slice of history, its treasures revealing the rich tapestry of Rome's past.   Now, let your senses transport you to the Italian countryside, where the ruins of a long-lost Roman amphitheater lie hidden, a key to unlocking the secrets of the past. The journey through the bustling city streets and rustic countryside is a testament to Rome's grandeur.  This is Rome, a city where history breathes from every stone, where the old collides with the new, and where the echo of the emperors still rings in the air. Step into Rome and walk through history.\n",
      "\n",
      "🎬 Referenced Videos: zxKPjD8urG4, evmyQGmuzqA, k4P5W1DKTBI\n",
      "\n",
      "🤔 Follow-up: do you want to know What secrets or discoveries might the archaeologists uncover from the newly found Roman amphitheater?? (yes/no)\n",
      "👋 Thanks for exploring with us!\n"
     ]
    }
   ],
   "source": [
    "def retrieve_context(pinecone_index, query_text, openai_client, top_k=5):\n",
    "    query_embedding_response = openai_client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=[query_text]\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "\n",
    "    results = pinecone_index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    retrieved_documents = []\n",
    "    for match in results.matches:\n",
    "        retrieved_documents.append(\n",
    "            Document(\n",
    "                page_content=match.metadata.get('text', ''),\n",
    "                metadata={\n",
    "                    \"video_id\": match.metadata.get('video_id', 'Unknown ID'),\n",
    "                    \"video_title\": match.metadata.get('video_title', 'Unknown Video'),\n",
    "                    \"score\": match.score\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    return retrieved_documents\n",
    "\n",
    "\n",
    "def format_context(documents):\n",
    "    context_string = \"\"\n",
    "    video_references = set()\n",
    "    for i, doc in enumerate(documents):\n",
    "        cleaned_text = re.sub(r'^\\s*[\\n\\s.]+', '', doc.page_content).strip()\n",
    "        context_string += f\"--- Document {i+1} (From Video: {doc.metadata.get('video_title', 'N/A')}, Score: {doc.metadata.get('score'):.3f}) ---\\n\"\n",
    "        context_string += f\"{cleaned_text}\\n\\n\"\n",
    "        video_references.add(doc.metadata.get('video_title', 'Unknown Video'))\n",
    "    return context_string, list(video_references)\n",
    "\n",
    "\n",
    "def safe_parse_json(llm_output):\n",
    "    import json\n",
    "    try:\n",
    "        return json.loads(llm_output)\n",
    "    except json.JSONDecodeError:\n",
    "        # Basic cleaning and retry (if needed)\n",
    "        cleaned = llm_output.strip().replace('\\n', ' ').replace('\\r', '')\n",
    "        try:\n",
    "            return json.loads(cleaned)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"❌ Still can't parse JSON:\", e)\n",
    "            print(\"🧾 Raw output:\", llm_output)\n",
    "            return None\n",
    "\n",
    "\n",
    "class ImmersiveStoryAgent:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "\n",
    "        self.openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "        pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "        if not pinecone_api_key:\n",
    "            raise ValueError(\"PINECONE_API_KEY not set.\")\n",
    "\n",
    "        pc = Pinecone(api_key=pinecone_api_key)\n",
    "        self.index_name = \"preprocessed-transcripts\"\n",
    "        if self.index_name not in [index.name for index in pc.list_indexes()]:\n",
    "            raise FileNotFoundError(f\"Pinecone index '{self.index_name}' not found.\")\n",
    "        self.pinecone_index = pc.Index(self.index_name)\n",
    "\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=\"gpt-4\",\n",
    "            temperature=0.85,\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "\n",
    "        self.qa_llm = ChatOpenAI(\n",
    "            model=\"gpt-4\",\n",
    "            temperature=0.2,\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "\n",
    "        self.story_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\", \"video_references_list\"],\n",
    "            template=\"\"\"\n",
    "You are a master storyteller guiding a vivid, immersive journey through ancient history.\n",
    "\n",
    "Create a unique, engaging introduction that draws the listener into the location or topic: \"{question}\"\n",
    "\n",
    "Use vivid sensory details — what they might see, hear, feel, or smell — to make the setting come alive.\n",
    "\n",
    "Only use information from the context. If it's not enough, say: \"I can't answer that based on the available context.\"\n",
    "\n",
    "---\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Video References List: {video_references_list}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "---\n",
    "\n",
    "Now write the immersive story. Respond in this JSON format:\n",
    "\n",
    "{{\n",
    "  \"story\": \"Your immersive story goes here\",\n",
    "  \"video_references\": [\"List of relevant video titles mentioned in the story\"]\n",
    "}}\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "        self.qa_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\"],\n",
    "            template=\"\"\"\n",
    "Answer the question using only the information from the context below. If you don't know the answer, say \"I can't answer that based on the available context.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "        )\n",
    "\n",
    "        self.story_chain = LLMChain(llm=self.llm, prompt=self.story_prompt)\n",
    "        self.qa_chain = LLMChain(llm=self.qa_llm, prompt=self.qa_prompt)\n",
    "        self.memory = SimpleConversationMemory(max_history=4)\n",
    "\n",
    "    def generate_story(self, destination):\n",
    "        session_id = destination.lower().strip()\n",
    "\n",
    "        # Augment query with recent context for follow-ups only if this is NOT a follow-up question (handled in main loop)\n",
    "        augmented_query = destination\n",
    "\n",
    "        print(f\"🗺 Destination/Query: {destination}\")\n",
    "        print(\"🔍 Retrieving context...\")\n",
    "\n",
    "        matches = retrieve_context(self.pinecone_index, augmented_query, self.openai_client, top_k=5)\n",
    "\n",
    "        if not matches:\n",
    "            return {\n",
    "                \"story\": \"I can't find enough information about that topic. Please try another destination or ask a specific question.\",\n",
    "                \"video_references\": []\n",
    "            }\n",
    "\n",
    "        context, video_titles = format_context(matches)\n",
    "        print(\"📖 Generating immersive story...\")\n",
    "\n",
    "        try:\n",
    "            raw_output = self.story_chain.run(\n",
    "                question=augmented_query,\n",
    "                context=context,\n",
    "                video_references_list=\", \".join(video_titles)\n",
    "            )\n",
    "            parsed = safe_parse_json(raw_output)\n",
    "            if not parsed or \"story\" not in parsed:\n",
    "                raise ValueError(\"Missing expected keys in story output\")\n",
    "\n",
    "            self.memory.add_qa_pair(destination, parsed['story'], session_id)\n",
    "\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            print(\"❌ Error during story generation:\", e)\n",
    "            traceback.print_exc()\n",
    "            return {\n",
    "                \"story\": \"An error occurred while generating the story.\",\n",
    "                \"video_references\": []\n",
    "            }\n",
    "\n",
    "    def answer_question(self, topic, question):\n",
    "        session_id = topic.lower().strip()\n",
    "\n",
    "        # Always augment question with recent context for follow-ups (if you want)\n",
    "        augmented_query = question\n",
    "\n",
    "        matches = retrieve_context(self.pinecone_index, augmented_query, self.openai_client, top_k=5)\n",
    "        context, _ = format_context(matches)\n",
    "\n",
    "        try:\n",
    "            answer = self.qa_chain.invoke({\n",
    "                \"question\": augmented_query,\n",
    "                \"context\": context\n",
    "            }).content\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(\"❌ Error during answering:\", e)\n",
    "            return \"I can't answer that based on the available context.\"\n",
    "\n",
    "    def ask_follow_up(self, current_topic):\n",
    "        matches = retrieve_context(self.pinecone_index, current_topic, self.openai_client, top_k=3)\n",
    "        context, _ = format_context(matches)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert historian. Based only on the context below, suggest one engaging follow-up question \n",
    "that would help the user continue exploring the story about \"{current_topic}\". \n",
    "\n",
    "If the context doesn't provide enough information for a good question, say \"No suitable follow-up question found.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            question = response.content.strip()\n",
    "            if question.lower() == \"no suitable follow-up question found.\":\n",
    "                return None\n",
    "            return question\n",
    "        except Exception as e:\n",
    "            print(\"❌ Error generating follow-up:\", e)\n",
    "            return None\n",
    "\n",
    "\n",
    "def is_question(text):\n",
    "    question_words = [\n",
    "        \"where\", \"what\", \"who\", \"when\", \"why\", \"how\",\n",
    "        \"is\", \"are\", \"do\", \"does\", \"did\", \"can\", \"could\", \"would\", \"should\", \"which\"\n",
    "    ]\n",
    "    text = text.strip().lower()\n",
    "    return any(text.startswith(qw) for qw in question_words)\n",
    "\n",
    "\n",
    "def print_story_and_followup(story_output):\n",
    "    print(\"\\n📚 Your Immersive Journey:\\n\")\n",
    "    print(\"📝 Story:\\n\", story_output.get(\"story\", \"No story generated.\"))\n",
    "\n",
    "    if story_output.get(\"video_references\"):\n",
    "        print(\"\\n🎬 Referenced Videos:\", \", \".join(story_output[\"video_references\"]))\n",
    "    else:\n",
    "        print(\"📼 No specific video references.\")\n",
    "\n",
    "    follow_up_question = None\n",
    "    if \"story\" in story_output:\n",
    "        # Attempt to get a follow-up question based on the current story context\n",
    "        follow_up_question = agent.ask_follow_up(story_output[\"story\"][:1000])  # Limit prompt size\n",
    "\n",
    "    if follow_up_question:\n",
    "        print(f\"\\n🤔 Follow-up: do you want to know {follow_up_question}? (yes/no)\")\n",
    "        return True, follow_up_question\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "\n",
    "def main():\n",
    "    global agent\n",
    "    agent = ImmersiveStoryAgent()\n",
    "\n",
    "    print(\"🎭 Welcome to Immersive Storytelling!\")\n",
    "    print(\"🌍 Where would you like to go today?\")\n",
    "    print(\"   ✨ Options: Great Pyramids, Roman Forum, Ancient Greece, Machu Picchu, Mesopotamia, Sangam Tamil Civilization\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    current_topic = None\n",
    "    follow_up_question = None\n",
    "    follow_up_mode = False\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\n🧭 Your input (type 'exit' to quit, 'back' to choose a new place): \").strip()\n",
    "\n",
    "        if not user_input:\n",
    "            continue\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"👋 Thanks for exploring with us!\")\n",
    "            break\n",
    "        if user_input.lower() == \"back\":\n",
    "            print(\"🔄 Resetting the journey. Where would you like to go now?\")\n",
    "            current_topic = None\n",
    "            follow_up_mode = False\n",
    "            continue\n",
    "\n",
    "        # Check if user wants to go to a new location (match locations exactly or loosely)\n",
    "        known_locations = [\n",
    "            \"Great Pyramids\", \"Roman Forum\", \"Ancient Greece\",\n",
    "            \"Machu Picchu\", \"Mesopotamia\", \"Sangam Tamil Civilization\",\n",
    "            \"Rome\"\n",
    "        ]\n",
    "\n",
    "        # Detect if user input mentions a known location\n",
    "        detected_location = None\n",
    "        for loc in known_locations:\n",
    "            if loc.lower() in user_input.lower():\n",
    "                detected_location = loc\n",
    "                break\n",
    "\n",
    "        # If user typed a known location, start story there\n",
    "        if detected_location:\n",
    "            current_topic = detected_location\n",
    "            story_output = agent.generate_story(current_topic)\n",
    "            follow_up_mode, follow_up_question = print_story_and_followup(story_output)\n",
    "            continue\n",
    "\n",
    "        # If we are in follow-up mode (user answering yes/no to follow-up)\n",
    "        if follow_up_mode:\n",
    "            if user_input.lower() == \"yes\":\n",
    "                if follow_up_question:\n",
    "                    # Strictly continue story based on the follow-up question ONLY\n",
    "                    story_output = agent.generate_story(follow_up_question)\n",
    "                    follow_up_mode, follow_up_question = print_story_and_followup(story_output)\n",
    "                    # Update current topic to follow-up question for future context\n",
    "                    current_topic = follow_up_question\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"No follow-up question to continue with.\")\n",
    "                    follow_up_mode = False\n",
    "                    continue\n",
    "            elif user_input.lower() == \"no\":\n",
    "                print(\"Okay, feel free to ask another question or choose a new location.\")\n",
    "                follow_up_mode = False\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Please answer with 'yes' or 'no'.\")\n",
    "                continue\n",
    "\n",
    "        # If input looks like a general question and we have a current topic\n",
    "        if current_topic and is_question(user_input):\n",
    "            answer = agent.answer_question(current_topic, user_input)\n",
    "            print(\"\\n💬 Answer:\\n\", answer)\n",
    "            print(f\"\\n🤔 Do you want to continue with the story of {current_topic}? (yes/no)\")\n",
    "            follow_up_mode = True\n",
    "            follow_up_question = None  # Reset follow-up question until new one generated\n",
    "            continue\n",
    "\n",
    "        # If no current topic, prompt user to pick location or ask question\n",
    "        if not current_topic:\n",
    "            print(\"I didn't catch a location. Please choose a location from the options or ask a question.\")\n",
    "            continue\n",
    "\n",
    "        # If input is none of above, just remind user\n",
    "        print(\"I didn't understand that. Please select a location or ask a relevant question.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90348e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

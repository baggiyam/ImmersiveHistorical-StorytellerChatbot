{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ee7b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from context_format import retrieve_context, format_context\n",
    "from SimpleConversationMemory import SimpleConversationMemory\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pinecone import Pinecone, ServerlessSpec \n",
    "import uuid\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain_core.documents import Document \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import re\n",
    "import pyttsx3\n",
    "import uuid\n",
    "from IPython.display import Audio, display\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3c16dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSManager:\n",
    "    def __init__(self, rate=150, volume=0.9):\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.engine.setProperty(\"rate\", rate)\n",
    "        self.engine.setProperty(\"volume\", volume)\n",
    "\n",
    "    def speak(self, text):\n",
    "        if not text:\n",
    "            return\n",
    "        try:\n",
    "            self.engine.say(text)\n",
    "            self.engine.runAndWait()\n",
    "        except Exception as e:\n",
    "            print(\"[TTS error]\", e)\n",
    "\n",
    "tts_manager = TTSManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0740219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse_json(llm_output: str):\n",
    "    try:\n",
    "        return json.loads(llm_output)\n",
    "    except json.JSONDecodeError:\n",
    "        cleaned = llm_output.strip()\n",
    "        cleaned = re.sub(r\"(?<!\\\\)\\\\n\", \"\\\\\\\\n\", cleaned)\n",
    "        cleaned = re.sub(r\"(?<!\\\\)\\\\\", r\"\\\\\\\\\", cleaned)\n",
    "        cleaned = re.sub(r\"\\n\", \"\\\\n\", cleaned)\n",
    "        try:\n",
    "            return json.loads(cleaned)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"❌ Still can't parse JSON after cleaning:\", e)\n",
    "            print(\"🧾 Raw output:\", llm_output)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "045b0aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎭 Welcome to Immersive Storytelling!\n",
      "🌍 Type a location to start your journey.\n",
      "   ✨ Options: Great Pyramids, Roman Forum, Ancient Greece, Machu Picchu, Mesopotamia, Sangam Tamil Civilization, Rome\n",
      "------------------------------------------------------------------\n",
      "\n",
      "📚 Your Immersive Journey:\n",
      "📝 Story: Let me transport your senses back in time to ancient Rome, the world's first superpower. Picture yourself on the hills casting a watchful eye over a fortified settlement. The air is pure, a river flows conveniently nearby, and the sea, a handy resource, lies within your reach. This is the place chosen by gods and men alike, a land destined for glory. Over the course of 500 years, the settlement morphs into a powerful republic, and finally, an empire. As you navigate through the city, you can't miss the grand amphitheater at its heart; the Colosseum, an enduring symbol of the Roman Empire, famous for its legendary gladiator contests. Now wander a little further, you'll stumble upon the majestic Basilica of Santa Francesca Romana, its stunning bell tower standing testimony to the 12th century. As you round the corner, you'll find a museum installed inside another archaeological area built by Emperor Hadrian, the same man who created the Hadrian Wall dividing Scotland from England, who restored the Pantheon, and who constructed the St. Angel Castle.\n",
      "\n",
      "🎬 Referenced Videos: zxKPjD8urG4, evmyQGmuzqA, k4P5W1DKTBI\n",
      "❓ Suggested Follow-up: Can you tell me more about the technology advancements of the ancient Romans?\n",
      "[TTS error] run loop already started\n"
     ]
    }
   ],
   "source": [
    "# === Conversation memory ===\n",
    "class SimpleConversationMemory:\n",
    "    def __init__(self, max_history=4):\n",
    "        self.max_history = max_history\n",
    "        self.history = []\n",
    "    \n",
    "    def add_qa_pair(self, question, answer, topic=None):\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'topic': topic,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "        if len(self.history) > self.max_history:\n",
    "            self.history.pop(0)\n",
    "    \n",
    "    def get_recent(self, count=1):\n",
    "        return self.history[-count:] if self.history else []\n",
    "\n",
    "# === Context retrieval functions ===\n",
    "def retrieve_context(index, query, oa_client, top_k=5):\n",
    "    emb = oa_client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\", input=[query]\n",
    "    ).data[0].embedding\n",
    "\n",
    "    res = index.query(vector=emb, top_k=top_k, include_metadata=True)\n",
    "    docs = [\n",
    "        Document(\n",
    "            page_content=m.metadata.get(\"text\", \"\"),\n",
    "            metadata={\n",
    "                \"video_id\":    m.metadata.get(\"video_id\", \"Unknown ID\"),\n",
    "                \"video_title\": m.metadata.get(\"video_title\", \"Unknown Video\"),\n",
    "                \"score\":       m.score,\n",
    "            },\n",
    "        )\n",
    "        for m in res.matches\n",
    "    ]\n",
    "    return docs\n",
    "\n",
    "def format_context(docs):\n",
    "    ctx, vids = \"\", set()\n",
    "    for i, d in enumerate(docs):\n",
    "        txt = re.sub(r\"^\\s*[\\n\\s.]+\", \"\", d.page_content).strip()\n",
    "        ctx += (\n",
    "            f\"--- Document {i+1} \"\n",
    "            f\"(Video: {d.metadata.get('video_title','N/A')}, \"\n",
    "            f\"Score: {d.metadata.get('score'):.3f}) ---\\n{txt}\\n\\n\"\n",
    "        )\n",
    "        vids.add(d.metadata.get(\"video_title\", \"Unknown Video\"))\n",
    "    return ctx, list(vids)\n",
    "\n",
    "# === Main Agent class ===\n",
    "class ImmersiveStoryAgent:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        \n",
    "        self.oa = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        \n",
    "        pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "        idx_name = \"preprocessed-transcripts\"\n",
    "        if idx_name not in [i.name for i in pc.list_indexes()]:\n",
    "            raise RuntimeError(f\"Pinecone index '{idx_name}' not found.\")\n",
    "        self.index = pc.Index(idx_name)\n",
    "        \n",
    "        self.llm = ChatOpenAI(model=\"gpt-4\", temperature=0.85)\n",
    "        self.qa_llm = ChatOpenAI(model=\"gpt-4\", temperature=0.2)\n",
    "        \n",
    "        self.story_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\", \"video_references_list\"],\n",
    "            template=\"\"\"\n",
    "You are a master storyteller guiding a vivid, immersive journey through ancient history.\n",
    "\n",
    "Create an engaging introduction that draws the listener into the location or topic: \"{question}\"\n",
    "\n",
    "Use ONLY the information in the context. If the context is insufficient,\n",
    "respond exactly: \"I can't answer that based on the available context.\"\n",
    "\n",
    "---\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Video References List: {video_references_list}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "---\n",
    "\n",
    "Respond in this JSON format:\n",
    "\n",
    "{{\n",
    "  \"story\": \"Your immersive story...\",\n",
    "  \"video_references\": [\"Video title 1\",\"Video title 2\"],\n",
    "  \"suggested_followup\": \"A suggested follow-up question about this story\"\n",
    "}}\n",
    "\"\"\"\n",
    "        )\n",
    "        \n",
    "        self.qa_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\"],\n",
    "            template=\"\"\"\n",
    "Answer the question using ONLY the context below.\n",
    "If the context is insufficient, say exactly:\n",
    "\"I can't answer that based on the available context.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "        )\n",
    "        \n",
    "        self.story_chain = LLMChain(llm=self.llm, prompt=self.story_prompt)\n",
    "        self.qa_chain = LLMChain(llm=self.qa_llm, prompt=self.qa_prompt)\n",
    "        self.memory = SimpleConversationMemory(max_history=4)\n",
    "        \n",
    "        self.current_location = None\n",
    "        self.current_story = None\n",
    "        self.waiting_for_followup = False\n",
    "        self.followup_question = None\n",
    "        self.location_options = [\n",
    "            \"Great Pyramids\", \"Roman Forum\", \"Ancient Greece\", \n",
    "            \"Machu Picchu\", \"Mesopotamia\", \"Sangam Tamil Civilization\", \"Rome\"\n",
    "        ]\n",
    "    \n",
    "    def generate_story(self, topic):\n",
    "        self.current_location = topic\n",
    "        docs = retrieve_context(self.index, topic, self.oa, top_k=5)\n",
    "        if not docs:\n",
    "            return {\n",
    "                \"story\": \"I can't answer that based on the available context.\",\n",
    "                \"video_references\": [],\n",
    "                \"suggested_followup\": None\n",
    "            }\n",
    "        \n",
    "        ctx, vids = format_context(docs)\n",
    "        if len(ctx.strip()) < 50:\n",
    "            return {\n",
    "                \"story\": \"I can't answer that based on the available context.\",\n",
    "                \"video_references\": [],\n",
    "                \"suggested_followup\": None\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            raw = self.story_chain.invoke({\n",
    "                \"question\": topic,\n",
    "                \"context\": ctx,\n",
    "                \"video_references_list\": \", \".join(vids)\n",
    "            })\n",
    "            \n",
    "            if hasattr(raw, \"text\"):\n",
    "                output = raw.text\n",
    "            elif hasattr(raw, \"content\"):\n",
    "                output = raw.content\n",
    "            elif isinstance(raw, dict) and \"text\" in raw:\n",
    "                output = raw[\"text\"]\n",
    "            else:\n",
    "                output = str(raw)\n",
    "            \n",
    "            parsed = safe_parse_json(output)\n",
    "            \n",
    "            if not parsed or not parsed.get(\"story\"):\n",
    "                raise ValueError(\"No story generated\")\n",
    "                \n",
    "            self.current_story = parsed[\"story\"]\n",
    "            self.followup_question = parsed.get(\"suggested_followup\")\n",
    "            self.waiting_for_followup = True if self.followup_question else False\n",
    "            \n",
    "            self.memory.add_qa_pair(topic, parsed[\"story\"], topic.lower())\n",
    "            return parsed\n",
    "            \n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return {\n",
    "                \"story\": f\"An error occurred while generating the story: {str(e)}\",\n",
    "                \"video_references\": [],\n",
    "                \"suggested_followup\": None\n",
    "            }\n",
    "    \n",
    "    def answer_question(self, topic, question):\n",
    "        docs = retrieve_context(self.index, question, self.oa, top_k=5)\n",
    "        ctx, _ = format_context(docs)\n",
    "        \n",
    "        if len(ctx.strip()) >= 50:\n",
    "            try:\n",
    "                resp = self.qa_chain.invoke({\n",
    "                    \"question\": question,\n",
    "                    \"context\": ctx\n",
    "                })\n",
    "                \n",
    "                if hasattr(resp, \"text\"):\n",
    "                    answer_text = resp.text\n",
    "                elif hasattr(resp, \"content\"):\n",
    "                    answer_text = resp.content\n",
    "                elif isinstance(resp, dict) and \"text\" in resp:\n",
    "                    answer_text = resp[\"text\"]\n",
    "                else:\n",
    "                    answer_text = str(resp)\n",
    "                \n",
    "                if answer_text.strip():\n",
    "                    self.followup_question = self.ask_follow_up(answer_text)\n",
    "                    self.waiting_for_followup = True if self.followup_question else False\n",
    "                    return answer_text.strip()\n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        try:\n",
    "            fallback_resp = self.qa_llm.invoke(question)\n",
    "            answer_text = fallback_resp.content if hasattr(fallback_resp, \"content\") else str(fallback_resp)\n",
    "            self.waiting_for_followup = False\n",
    "            return answer_text.strip()\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            return \"I couldn't find an answer to that question.\"\n",
    "    \n",
    "    def ask_follow_up(self, snippet):\n",
    "        prompt = (\n",
    "            \"Suggest ONE engaging follow-up question based only on this text:\\n\"\n",
    "            f\"{snippet}\\n\\n\"\n",
    "            \"If no good question, reply: No suitable follow-up question found.\"\n",
    "        )\n",
    "        try:\n",
    "            resp = self.llm.invoke(prompt)\n",
    "            if hasattr(resp, \"content\"):\n",
    "                resp_text = resp.content.strip()\n",
    "            elif isinstance(resp, str):\n",
    "                resp_text = resp.strip()\n",
    "            else:\n",
    "                resp_text = str(resp).strip()\n",
    "            \n",
    "            if resp_text.lower().startswith(\"no suitable\"):\n",
    "                return None\n",
    "            return resp_text\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "# === Main interaction loop ===\n",
    "def main():\n",
    "    agent = ImmersiveStoryAgent()\n",
    "    yes_answers = {'yes', 'ok', 'tell me', 'continue', 'proceed'}\n",
    "    \n",
    "    print(\"🎭 Welcome to Immersive Storytelling!\")\n",
    "    print(\"🌍 Type a location to start your journey.\")\n",
    "    print(\"   ✨ Options: \" + \", \".join(agent.location_options))\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    \n",
    "    while True:\n",
    "        if agent.waiting_for_followup:\n",
    "            user_input = input(f\"\\n🤔 Would you like to know more? (yes/no) or ask something else: \").strip().lower()\n",
    "            \n",
    "            if user_input == 'exit':\n",
    "                break\n",
    "            \n",
    "            new_location = None\n",
    "            for loc in agent.location_options:\n",
    "                if loc.lower() in user_input:\n",
    "                    new_location = loc\n",
    "                    break\n",
    "            \n",
    "            if user_input in yes_answers:\n",
    "                # Continue follow-up\n",
    "                answer = agent.answer_question(agent.current_location, agent.followup_question)\n",
    "                print(f\"\\n📚 Your Immersive Journey:\")\n",
    "                print(f\"💬 Answer: {answer}\")\n",
    "                if agent.followup_question:\n",
    "                    tts_manager.speak(answer)\n",
    "            \n",
    "            else:\n",
    "                # End follow-up immediately\n",
    "                agent.waiting_for_followup = False\n",
    "                \n",
    "                if new_location:\n",
    "                    # New location requested\n",
    "                    response = agent.generate_story(new_location)\n",
    "                    print(f\"\\n📚 Your Immersive Journey:\")\n",
    "                    print(f\"📝 Story: {response['story']}\")\n",
    "                    if response['video_references']:\n",
    "                        print(f\"\\n🎬 Referenced Videos: {', '.join(response['video_references'])}\")\n",
    "                    if response['suggested_followup']:\n",
    "                        print(f\"❓ Suggested Follow-up: {response['suggested_followup']}\")\n",
    "                    \n",
    "                    tts_manager.speak(response['story'])\n",
    "                \n",
    "                else:\n",
    "                    # Handle question on current location\n",
    "                    answer = agent.answer_question(agent.current_location, user_input)\n",
    "                    print(f\"\\n💬 Answer: {answer}\")\n",
    "                    tts_manager.speak(answer)\n",
    "        else:\n",
    "            user_input = input(\"\\n🗺️ Choose a location or ask a question (type 'exit' to quit): \").strip()\n",
    "            if user_input.lower() == 'exit':\n",
    "                print(\"👋 Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            new_location = None\n",
    "            for loc in agent.location_options:\n",
    "                if loc.lower() == user_input.lower():\n",
    "                    new_location = loc\n",
    "                    break\n",
    "            \n",
    "            if new_location:\n",
    "                response = agent.generate_story(new_location)\n",
    "                print(f\"\\n📚 Your Immersive Journey:\")\n",
    "                print(f\"📝 Story: {response['story']}\")\n",
    "                if response['video_references']:\n",
    "                    print(f\"\\n🎬 Referenced Videos: {', '.join(response['video_references'])}\")\n",
    "                if response['suggested_followup']:\n",
    "                    print(f\"❓ Suggested Follow-up: {response['suggested_followup']}\")\n",
    "                \n",
    "                tts_manager.speak(response['story'])\n",
    "            else:\n",
    "                if agent.current_location:\n",
    "                    answer = agent.answer_question(agent.current_location, user_input)\n",
    "                    print(f\"\\n💬 Answer: {answer}\")\n",
    "                    tts_manager.speak(answer)\n",
    "                else:\n",
    "                    print(\"⚠️ Please select a location first.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90348e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

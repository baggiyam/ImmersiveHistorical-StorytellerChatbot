{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee7b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from context_format import retrieve_context, format_context\n",
    "from SimpleConversationMemory import SimpleConversationMemory\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pinecone import Pinecone, ServerlessSpec \n",
    "import uuid\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain_core.documents import Document \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import re\n",
    "import pyttsx3\n",
    "import uuid\n",
    "from IPython.display import Audio, display\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c16dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSManager:\n",
    "    def __init__(self, rate=150, volume=0.9):\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.engine.setProperty(\"rate\", rate)\n",
    "        self.engine.setProperty(\"volume\", volume)\n",
    "\n",
    "    def speak(self, text):\n",
    "        if not text:\n",
    "            return\n",
    "        try:\n",
    "            self.engine.say(text)\n",
    "            self.engine.runAndWait()\n",
    "        except Exception as e:\n",
    "            print(\"[TTS error]\", e)\n",
    "\n",
    "tts_manager = TTSManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0740219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse_json(llm_output: str):\n",
    "    try:\n",
    "        return json.loads(llm_output)\n",
    "    except json.JSONDecodeError:\n",
    "        cleaned = llm_output.strip()\n",
    "        cleaned = re.sub(r\"(?<!\\\\)\\\\n\", \"\\\\\\\\n\", cleaned)\n",
    "        cleaned = re.sub(r\"(?<!\\\\)\\\\\", r\"\\\\\\\\\", cleaned)\n",
    "        cleaned = re.sub(r\"\\n\", \"\\\\n\", cleaned)\n",
    "        try:\n",
    "            return json.loads(cleaned)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"❌ Still can't parse JSON after cleaning:\", e)\n",
    "            print(\"🧾 Raw output:\", llm_output)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045b0aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bshanmugam/Documents/FinalStory/ImmersiveHistorical-StorytellerChatbot/myenv311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/7j/c3cwb7d17c1cfkhmkrqtw4q00000gn/T/ipykernel_40999/1047336686.py:113: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  self.story_chain = LLMChain(llm=self.llm, prompt=self.story_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎭 Welcome to Immersive Storytelling!\n",
      "🌍 Type a location to start your journey.\n",
      "   ✨ Options: Great Pyramids, Roman Forum, Ancient Greece, Machu Picchu, Mesopotamia, Sangam Tamil Civilization, Rome\n",
      "------------------------------------------------------------------\n",
      "\n",
      "📚 Your Immersive Journey:\n",
      "📝 Story: Journey with me now to a place where great ambition and relentless determination carved out history's first superpower from the ancient earth. Picture yourself in Rome, a city born from a unique blend of divine selection and earthly advantage, chosen by gods and men together for glory. Hills teeming with pure, life-giving air, a river flowing conveniently across the landscape, and a sea at hand for their needs. This splendid city did not start as a superpower. Rather, over 500 years, it grew from a fortified settlement, evolving into a mighty republic, and finally blossoming into a breathtaking empire whose emperors' ambitions knew no bounds. Technology, in the hands of these Romans, reached unparalleled heights, revealing a maritime graveyard, lost marvels, and feats of engineering that boggle the mind even today. Nestled in the heart of Rome, the enduring symbol of this empire, the Colosseum stands, famous for its gladiatorial spectacles of brutality and death. Its scale and ambition remain legendary. Now, as we walk down a little road to the right, a majestic view of the Basilica of Santa Francesca Romana unfurls, its charming bell tower harking back to the 12th century. This journey is only beginning, dear listener, as we continue to unearth the treasures of Rome, the world's first superpower.\n",
      "\n",
      "🎬 Referenced Videos: zxKPjD8urG4, evmyQGmuzqA, k4P5W1DKTBI\n",
      "❓ Suggested Follow-up: What were the major technological achievements of Ancient Rome that contributed to its status as a superpower?\n",
      "\n",
      "📚 Your Immersive Journey:\n",
      "💬 Answer: The context mentions that the Romans took technology to a whole other level, with their greatest ever feat of engineering being a lost marvel on a distant Mediterranean shore. They also had engineering skills that astonished their rivals. Another major technological achievement was their control of the sea, which was essential for feeding their population.\n",
      "\n",
      "💬 Answer: I can't answer that based on the available context.\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 321\u001b[39m\n\u001b[32m    318\u001b[39m                     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ Please select a location first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 287\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    283\u001b[39m     tts_manager.speak(response[\u001b[33m'\u001b[39m\u001b[33mstory\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Handle question on current location\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     answer = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43manswer_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m💬 Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    289\u001b[39m     tts_manager.speak(answer)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 181\u001b[39m, in \u001b[36mImmersiveStoryAgent.answer_question\u001b[39m\u001b[34m(self, topic, question)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manswer_question\u001b[39m(\u001b[38;5;28mself\u001b[39m, topic, question):\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     docs = \u001b[43mretrieve_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     ctx, _ = format_context(docs)\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ctx.strip()) >= \u001b[32m50\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mretrieve_context\u001b[39m\u001b[34m(index, query, oa_client, top_k)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve_context\u001b[39m(index, query, oa_client, top_k=\u001b[32m5\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     emb = \u001b[43moa_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-embedding-ada-002\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.data[\u001b[32m0\u001b[39m].embedding\n\u001b[32m     26\u001b[39m     res = index.query(vector=emb, top_k=top_k, include_metadata=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     27\u001b[39m     docs = [\n\u001b[32m     28\u001b[39m         Document(\n\u001b[32m     29\u001b[39m             page_content=m.metadata.get(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m res.matches\n\u001b[32m     37\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FinalStory/ImmersiveHistorical-StorytellerChatbot/myenv311/lib/python3.11/site-packages/openai/resources/embeddings.py:129\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    123\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    124\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m             ).tolist()\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FinalStory/ImmersiveHistorical-StorytellerChatbot/myenv311/lib/python3.11/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FinalStory/ImmersiveHistorical-StorytellerChatbot/myenv311/lib/python3.11/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "# === Conversation memory ===\n",
    "class SimpleConversationMemory:\n",
    "    def __init__(self, max_history=4):\n",
    "        self.max_history = max_history\n",
    "        self.history = []\n",
    "    \n",
    "    def add_qa_pair(self, question, answer, topic=None):\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'topic': topic,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "        if len(self.history) > self.max_history:\n",
    "            self.history.pop(0)\n",
    "    \n",
    "    def get_recent(self, count=1):\n",
    "        return self.history[-count:] if self.history else []\n",
    "\n",
    "# === Context retrieval functions ===\n",
    "def retrieve_context(index, query, oa_client, top_k=5):\n",
    "    emb = oa_client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\", input=[query]\n",
    "    ).data[0].embedding\n",
    "\n",
    "    res = index.query(vector=emb, top_k=top_k, include_metadata=True)\n",
    "    docs = [\n",
    "        Document(\n",
    "            page_content=m.metadata.get(\"text\", \"\"),\n",
    "            metadata={\n",
    "                \"video_id\":    m.metadata.get(\"video_id\", \"Unknown ID\"),\n",
    "                \"video_title\": m.metadata.get(\"video_title\", \"Unknown Video\"),\n",
    "                \"score\":       m.score,\n",
    "            },\n",
    "        )\n",
    "        for m in res.matches\n",
    "    ]\n",
    "    return docs\n",
    "\n",
    "def format_context(docs):\n",
    "    ctx, vids = \"\", set()\n",
    "    for i, d in enumerate(docs):\n",
    "        txt = re.sub(r\"^\\s*[\\n\\s.]+\", \"\", d.page_content).strip()\n",
    "        ctx += (\n",
    "            f\"--- Document {i+1} \"\n",
    "            f\"(Video: {d.metadata.get('video_title','N/A')}, \"\n",
    "            f\"Score: {d.metadata.get('score'):.3f}) ---\\n{txt}\\n\\n\"\n",
    "        )\n",
    "        vids.add(d.metadata.get(\"video_title\", \"Unknown Video\"))\n",
    "    return ctx, list(vids)\n",
    "\n",
    "# === Main Agent class ===\n",
    "class ImmersiveStoryAgent:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        \n",
    "        self.oa = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        \n",
    "        pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "        idx_name = \"preprocessed-transcripts\"\n",
    "        if idx_name not in [i.name for i in pc.list_indexes()]:\n",
    "            raise RuntimeError(f\"Pinecone index '{idx_name}' not found.\")\n",
    "        self.index = pc.Index(idx_name)\n",
    "        \n",
    "        self.llm = ChatOpenAI(model=\"gpt-4\", temperature=0.85)\n",
    "        self.qa_llm = ChatOpenAI(model=\"gpt-4\", temperature=0.2)\n",
    "        \n",
    "        self.story_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\", \"video_references_list\"],\n",
    "            template=\"\"\"\n",
    "You are a master storyteller guiding a vivid, immersive journey through ancient history.\n",
    "\n",
    "Create an engaging introduction that draws the listener into the location or topic: \"{question}\"\n",
    "\n",
    "Use ONLY the information in the context. If the context is insufficient,\n",
    "respond exactly: \"I can't answer that based on the available context.\"\n",
    "\n",
    "---\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Video References List: {video_references_list}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "---\n",
    "\n",
    "Respond in this JSON format:\n",
    "\n",
    "{{\n",
    "  \"story\": \"Your immersive story...\",\n",
    "  \"video_references\": [\"Video title 1\",\"Video title 2\"],\n",
    "  \"suggested_followup\": \"A suggested follow-up question about this story\"\n",
    "}}\n",
    "\"\"\"\n",
    "        )\n",
    "        \n",
    "        self.qa_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\"],\n",
    "            template=\"\"\"\n",
    "Answer the question using ONLY the context below.\n",
    "If the context is insufficient, say exactly:\n",
    "\"I can't answer that based on the available context.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "        )\n",
    "        \n",
    "        self.story_chain = LLMChain(llm=self.llm, prompt=self.story_prompt)\n",
    "        self.qa_chain = LLMChain(llm=self.qa_llm, prompt=self.qa_prompt)\n",
    "        self.memory = SimpleConversationMemory(max_history=4)\n",
    "        \n",
    "        self.current_location = None\n",
    "        self.current_story = None\n",
    "        self.waiting_for_followup = False\n",
    "        self.followup_question = None\n",
    "        self.location_options = [\n",
    "            \"Great Pyramids\", \"Roman Forum\", \"Ancient Greece\", \n",
    "            \"Machu Picchu\", \"Mesopotamia\", \"Sangam Tamil Civilization\", \"Rome\"\n",
    "        ]\n",
    "    \n",
    "    def generate_story(self, topic):\n",
    "        self.current_location = topic\n",
    "        docs = retrieve_context(self.index, topic, self.oa, top_k=5)\n",
    "        if not docs:\n",
    "            return {\n",
    "                \"story\": \"I can't answer that based on the available context.\",\n",
    "                \"video_references\": [],\n",
    "                \"suggested_followup\": None\n",
    "            }\n",
    "        \n",
    "        ctx, vids = format_context(docs)\n",
    "        if len(ctx.strip()) < 50:\n",
    "            return {\n",
    "                \"story\": \"I can't answer that based on the available context.\",\n",
    "                \"video_references\": [],\n",
    "                \"suggested_followup\": None\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            raw = self.story_chain.invoke({\n",
    "                \"question\": topic,\n",
    "                \"context\": ctx,\n",
    "                \"video_references_list\": \", \".join(vids)\n",
    "            })\n",
    "            \n",
    "            if hasattr(raw, \"text\"):\n",
    "                output = raw.text\n",
    "            elif hasattr(raw, \"content\"):\n",
    "                output = raw.content\n",
    "            elif isinstance(raw, dict) and \"text\" in raw:\n",
    "                output = raw[\"text\"]\n",
    "            else:\n",
    "                output = str(raw)\n",
    "            \n",
    "            parsed = safe_parse_json(output)\n",
    "            \n",
    "            if not parsed or not parsed.get(\"story\"):\n",
    "                raise ValueError(\"No story generated\")\n",
    "                \n",
    "            self.current_story = parsed[\"story\"]\n",
    "            self.followup_question = parsed.get(\"suggested_followup\")\n",
    "            self.waiting_for_followup = True if self.followup_question else False\n",
    "            \n",
    "            self.memory.add_qa_pair(topic, parsed[\"story\"], topic.lower())\n",
    "            return parsed\n",
    "            \n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return {\n",
    "                \"story\": f\"An error occurred while generating the story: {str(e)}\",\n",
    "                \"video_references\": [],\n",
    "                \"suggested_followup\": None\n",
    "            }\n",
    "    \n",
    "    def answer_question(self, topic, question):\n",
    "        docs = retrieve_context(self.index, question, self.oa, top_k=5)\n",
    "        ctx, _ = format_context(docs)\n",
    "        \n",
    "        if len(ctx.strip()) >= 50:\n",
    "            try:\n",
    "                resp = self.qa_chain.invoke({\n",
    "                    \"question\": question,\n",
    "                    \"context\": ctx\n",
    "                })\n",
    "                \n",
    "                if hasattr(resp, \"text\"):\n",
    "                    answer_text = resp.text\n",
    "                elif hasattr(resp, \"content\"):\n",
    "                    answer_text = resp.content\n",
    "                elif isinstance(resp, dict) and \"text\" in resp:\n",
    "                    answer_text = resp[\"text\"]\n",
    "                else:\n",
    "                    answer_text = str(resp)\n",
    "                \n",
    "                if answer_text.strip():\n",
    "                    self.followup_question = self.ask_follow_up(answer_text)\n",
    "                    self.waiting_for_followup = True if self.followup_question else False\n",
    "                    return answer_text.strip()\n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        try:\n",
    "            fallback_resp = self.qa_llm.invoke(question)\n",
    "            answer_text = fallback_resp.content if hasattr(fallback_resp, \"content\") else str(fallback_resp)\n",
    "            self.waiting_for_followup = False\n",
    "            return answer_text.strip()\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            return \"I couldn't find an answer to that question.\"\n",
    "    \n",
    "    def ask_follow_up(self, snippet):\n",
    "        prompt = (\n",
    "            \"Suggest ONE engaging follow-up question based only on this text:\\n\"\n",
    "            f\"{snippet}\\n\\n\"\n",
    "            \"If no good question, reply: No suitable follow-up question found.\"\n",
    "        )\n",
    "        try:\n",
    "            resp = self.llm.invoke(prompt)\n",
    "            if hasattr(resp, \"content\"):\n",
    "                resp_text = resp.content.strip()\n",
    "            elif isinstance(resp, str):\n",
    "                resp_text = resp.strip()\n",
    "            else:\n",
    "                resp_text = str(resp).strip()\n",
    "            \n",
    "            if resp_text.lower().startswith(\"no suitable\"):\n",
    "                return None\n",
    "            return resp_text\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "# === Main interaction loop ===\n",
    "def main():\n",
    "    agent = ImmersiveStoryAgent()\n",
    "    yes_answers = {'yes', 'ok', 'tell me', 'continue', 'proceed'}\n",
    "    \n",
    "    print(\"🎭 Welcome to Immersive Storytelling!\")\n",
    "    print(\"🌍 Type a location to start your journey.\")\n",
    "    print(\"   ✨ Options: \" + \", \".join(agent.location_options))\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    \n",
    "    while True:\n",
    "        if agent.waiting_for_followup:\n",
    "            user_input = input(f\"\\n🤔 Would you like to know more? (yes/no) or ask something else: \").strip().lower()\n",
    "            \n",
    "            if user_input == 'exit':\n",
    "                break\n",
    "            \n",
    "            new_location = None\n",
    "            for loc in agent.location_options:\n",
    "                if loc.lower() in user_input:\n",
    "                    new_location = loc\n",
    "                    break\n",
    "            \n",
    "            if user_input in yes_answers:\n",
    "                # Continue follow-up\n",
    "                answer = agent.answer_question(agent.current_location, agent.followup_question)\n",
    "                print(f\"\\n📚 Your Immersive Journey:\")\n",
    "                print(f\"💬 Answer: {answer}\")\n",
    "                if agent.followup_question:\n",
    "                    tts_manager.speak(answer)\n",
    "            \n",
    "            else:\n",
    "                # End follow-up immediately\n",
    "                agent.waiting_for_followup = False\n",
    "                \n",
    "                if new_location:\n",
    "                    # New location requested\n",
    "                    response = agent.generate_story(new_location)\n",
    "                    print(f\"\\n📚 Your Immersive Journey:\")\n",
    "                    print(f\"📝 Story: {response['story']}\")\n",
    "                    if response['video_references']:\n",
    "                        print(f\"\\n🎬 Referenced Videos: {', '.join(response['video_references'])}\")\n",
    "                    if response['suggested_followup']:\n",
    "                        print(f\"❓ Suggested Follow-up: {response['suggested_followup']}\")\n",
    "                    \n",
    "                    tts_manager.speak(response['story'])\n",
    "                \n",
    "                else:\n",
    "                    # Handle question on current location\n",
    "                    answer = agent.answer_question(agent.current_location, user_input)\n",
    "                    print(f\"\\n💬 Answer: {answer}\")\n",
    "                    tts_manager.speak(answer)\n",
    "        else:\n",
    "            user_input = input(\"\\n🗺️ Choose a location or ask a question (type 'exit' to quit): \").strip()\n",
    "            if user_input.lower() == 'exit':\n",
    "                print(\"👋 Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            new_location = None\n",
    "            for loc in agent.location_options:\n",
    "                if loc.lower() == user_input.lower():\n",
    "                    new_location = loc\n",
    "                    break\n",
    "            \n",
    "            if new_location:\n",
    "                response = agent.generate_story(new_location)\n",
    "                print(f\"\\n📚 Your Immersive Journey:\")\n",
    "                print(f\"📝 Story: {response['story']}\")\n",
    "                if response['video_references']:\n",
    "                    print(f\"\\n🎬 Referenced Videos: {', '.join(response['video_references'])}\")\n",
    "                if response['suggested_followup']:\n",
    "                    print(f\"❓ Suggested Follow-up: {response['suggested_followup']}\")\n",
    "                \n",
    "                tts_manager.speak(response['story'])\n",
    "            else:\n",
    "                if agent.current_location:\n",
    "                    answer = agent.answer_question(agent.current_location, user_input)\n",
    "                    print(f\"\\n💬 Answer: {answer}\")\n",
    "                    tts_manager.speak(answer)\n",
    "                else:\n",
    "                    print(\"⚠️ Please select a location first.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90348e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
